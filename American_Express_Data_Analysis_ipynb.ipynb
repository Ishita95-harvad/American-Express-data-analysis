{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5FAVwaJKPZ/ZLe4PxwqeE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishita95-harvad/American-Express-data-analysis/blob/main/American_Express_Data_Analysis_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Introduction**"
      ],
      "metadata": {
        "id": "vq4igOMs-gR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The American Express Data Analysis course offers a comprehensive exploration of data analytics techniques and tools. This program equips students with the skills to extract valuable insights from data, enabling informed decision-making. Participants will delve into data visualization, statistical analysis, and machine learning, while also focusing on real-world applications. Taught by industry experts, this course provides hands-on experience with data sets relevant to finance, customer behavior, and more. Whether you're a novice or experienced analyst, this course empowers you to harness the power of data for strategic advantage in the business world.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N_ljqMG89uf4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aSIfclhu9mJW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8-7ya4Omb97n",
        "outputId": "b1054b67-9c34-4d67-c6b8-de3b1a899958"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "v5NG-9h8-WMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "5dJ2oGawcBu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n",
        "import openpyxl\n",
        "import pandas as pd\n",
        "# Replace 'your_file_path.xlsx' with the actual path to your Excel file\n",
        "file_path = 'your_file_path.xlsx'\n",
        "try:\n",
        "    dataset = pd.read_excel(file_path, engine='openpyxl')\n",
        "    print(\"File loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at path: {file_path}\")\n",
        "    print(\"Please check the file path and ensure the file exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHSi-DkX9FUY",
        "outputId": "9c2c4c16-0a7d-4cad-cf48-bafa8487c521"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Error: File not found at path: your_file_path.xlsx\n",
            "Please check the file path and ensure the file exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file_path.xlsx' with the actual path to your Excel file\n",
        "file_path = 'your_file_path.xlsx'\n",
        "\n",
        "try:\n",
        "    dataset = pd.read_excel(file_path, engine='openpyxl') # Load the data into a variable named dataset.\n",
        "    print(\"File loaded successfully!\")\n",
        "\n",
        "    # Process data only if the file was loaded successfully\n",
        "    x = dataset.iloc[:, 0:-1].values\n",
        "    y = dataset.iloc[:, -1].values\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at path: {file_path}\")\n",
        "    print(\"Please check the file path and ensure the file exists.\")\n",
        "\n",
        "    # Handle the case where the file is not found, e.g., by assigning default values to x and y\n",
        "    x = None\n",
        "    y = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrjoBOj09kgJ",
        "outputId": "c5f86eaf-b025-4584-c88c-c4b2bf07decd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at path: your_file_path.xlsx\n",
            "Please check the file path and ensure the file exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJLdFK34cJhn",
        "outputId": "51d94182-7d1f-4d1f-c154-0cf94a25d089"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing American Express Data Analysis**"
      ],
      "metadata": {
        "id": "_HcdrrGu-ZcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorical Data"
      ],
      "metadata": {
        "id": "_EGxY37rcRta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gender coloumn: Label Encoding"
      ],
      "metadata": {
        "id": "ol7adWMdcSo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file_path.xlsx' with the actual path to your Excel file\n",
        "file_path = 'your_file_path.xlsx'\n",
        "\n",
        "try:\n",
        "    dataset = pd.read_excel(file_path, engine='openpyxl') # Load the data into a variable named dataset.\n",
        "    print(\"File loaded successfully!\")\n",
        "\n",
        "    # Process data only if the file was loaded successfully\n",
        "    x = dataset.iloc[:, 0:-1].values\n",
        "    y = dataset.iloc[:, -1].values\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at path: {file_path}\")\n",
        "    print(\"Please check the file path and ensure the file exists.\")\n",
        "\n",
        "    # Handle the case where the file is not found, e.g., by assigning default values to x and y\n",
        "    # Instead of assigning None, initialize x as an empty array to avoid TypeError later.\n",
        "    x = np.array([])  # Or provide a default DataFrame to dataset.\n",
        "    y = np.array([]) # Similar fix for y if it is used later\n",
        "\n",
        "    # You might also want to exit the program if the file is not found:\n",
        "    # import sys\n",
        "    # sys.exit(1)\n",
        "\n",
        "# Proceed with your code as before...\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder=LabelEncoder()\n",
        "\n",
        "# Check if x is empty before proceeding\n",
        "if x.size > 0:\n",
        "    x[:,2]=label_encoder.fit_transform(x[:,2])\n",
        "else:\n",
        "    print(\"x is empty, skipping Label Encoding for this step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuSDLGlE9vvb",
        "outputId": "90b2438b-1c92-40cb-fc0d-7efa20356d7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at path: your_file_path.xlsx\n",
            "Please check the file path and ensure the file exists.\n",
            "x is empty, skipping Label Encoding for this step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geography coloumn: One hot Encoding"
      ],
      "metadata": {
        "id": "uF1JToHrclXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ... (previous code to load data and handle FileNotFoundError) ...\n",
        "\n",
        "# Check if x is empty and has the correct shape\n",
        "if x.size > 0 and x.ndim == 2:\n",
        "    # Label Encoding for Gender column\n",
        "    label_encoder = LabelEncoder()\n",
        "    x[:, 2] = label_encoder.fit_transform(x[:, 2])\n",
        "\n",
        "    # One-Hot Encoding for Geography column\n",
        "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "    x = np.array(ct.fit_transform(x))\n",
        "else:\n",
        "    print(\"x is empty or has incorrect shape, skipping encoding steps.\")\n",
        "    # Handle the case where x is empty or has the wrong shape,\n",
        "    # e.g., by providing default data or exiting the program\n",
        "\n",
        "# ... (rest of your code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyacF1I898zV",
        "outputId": "2d57a757-525f-4e19-8eff-4acc6bfeb4ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x is empty or has incorrect shape, skipping encoding steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ... (previous code to load data and handle FileNotFoundError) ...\n",
        "\n",
        "# Check if x is empty and has the correct shape\n",
        "if x.size > 0 and x.ndim == 2:\n",
        "    # Label Encoding for Gender column\n",
        "    label_encoder = LabelEncoder()\n",
        "    x[:, 2] = label_encoder.fit_transform(x[:, 2])\n",
        "\n",
        "    # One-Hot Encoding for Geography column\n",
        "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "    x = np.array(ct.fit_transform(x))\n",
        "else:\n",
        "    print(\"x is empty or has incorrect shape, skipping encoding steps.\")\n",
        "    # Handle the case where x is empty or has the wrong shape,\n",
        "    # e.g., by providing default data or exiting the program\n",
        "\n",
        "# ... (rest of your code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABahI5LK-JZp",
        "outputId": "b9e75d12-5aec-48ee-dd53-f653df8aa5e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x is empty or has incorrect shape, skipping encoding steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(x)"
      ],
      "metadata": {
        "id": "dedgd519cs_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6786704-f0be-404a-84d3-213c928827a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting Dataset into Training & Test set"
      ],
      "metadata": {
        "id": "J3QOXYNOcwjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ... (previous code to load data and handle FileNotFoundError) ...\n",
        "\n",
        "# Check if x is empty and has the correct shape\n",
        "if x.size > 0 and x.ndim == 2:\n",
        "    # Label Encoding for Gender column\n",
        "    label_encoder = LabelEncoder()\n",
        "    x[:, 2] = label_encoder.fit_transform(x[:, 2])\n",
        "\n",
        "    # One-Hot Encoding for Geography column\n",
        "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "    x = np.array(ct.fit_transform(x))\n",
        "else:\n",
        "    print(\"x is empty or has incorrect shape, skipping encoding steps.\")\n",
        "    # Handle the case where x is empty or has the wrong shape,\n",
        "    # Instead of just printing a message, provide default data or exit\n",
        "    # Here, we'll create a small sample dataset for demonstration\n",
        "    x = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "    y = np.array([0, 1])\n",
        "\n",
        "# Now you can proceed with train_test_split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8Xat3Wr-SWm",
        "outputId": "378c3e43-cc3c-4cab-cbf7-dacb05bec07a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x is empty or has incorrect shape, skipping encoding steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "kKdvNAemc0T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ... (previous code to load data and handle FileNotFoundError) ...\n",
        "\n",
        "# Check if x is empty and has the correct shape\n",
        "if x.size > 0 and x.ndim == 2:\n",
        "    # Label Encoding for Gender column\n",
        "    label_encoder = LabelEncoder()\n",
        "    x[:, 2] = label_encoder.fit_transform(x[:, 2])\n",
        "\n",
        "    # One-Hot Encoding for Geography column\n",
        "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "    x = np.array(ct.fit_transform(x))\n",
        "else:\n",
        "    print(\"x is empty or has incorrect shape, skipping encoding steps.\")\n",
        "    # Handle the case where x is empty or has the wrong shape,\n",
        "    # Instead of just printing a message, provide default data or exit\n",
        "    # Here, we'll create a small sample dataset for demonstration\n",
        "    x = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "    y = np.array([0, 1])\n",
        "\n",
        "# Now you can proceed with train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0) # Splitting the dataset into the Training set and Test set\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "3kqbez4uMGm4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "1D0b5sUXc7Xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initilazation"
      ],
      "metadata": {
        "id": "EYlc7_M4dAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ann=tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "82Yj9kugc41V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "XKss-q1hdEok"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding second hidden Layer"
      ],
      "metadata": {
        "id": "E5umBveAdG-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n"
      ],
      "metadata": {
        "id": "3wasS4FvdI44"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding output Layer"
      ],
      "metadata": {
        "id": "nl0gT_9RdLJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "xdBQYJhsdO8h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ANN TRAINING**\n",
        "# Training on training dataset Compiling\n",
        "\n",
        "ANN"
      ],
      "metadata": {
        "id": "WgzS_cAwdR5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hCvD_cGGdaxj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(x_train, y_train, batch_size=32, epochs=120)"
      ],
      "metadata": {
        "id": "gjhTdRwPdcy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae48ed17-3524-4995-d61f-0ba75360b949"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.6931\n",
            "Epoch 2/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6926\n",
            "Epoch 3/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6921\n",
            "Epoch 4/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.6916\n",
            "Epoch 5/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.6911\n",
            "Epoch 6/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.6907\n",
            "Epoch 7/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.6902\n",
            "Epoch 8/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.6897\n",
            "Epoch 9/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.6892\n",
            "Epoch 10/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6887\n",
            "Epoch 11/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6882\n",
            "Epoch 12/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6877\n",
            "Epoch 13/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6872\n",
            "Epoch 14/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6867\n",
            "Epoch 15/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6862\n",
            "Epoch 16/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6857\n",
            "Epoch 17/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6852\n",
            "Epoch 18/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.6847\n",
            "Epoch 19/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6842\n",
            "Epoch 20/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6837\n",
            "Epoch 21/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6832\n",
            "Epoch 22/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6827\n",
            "Epoch 23/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6822\n",
            "Epoch 24/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6817\n",
            "Epoch 25/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6812\n",
            "Epoch 26/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6807\n",
            "Epoch 27/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6802\n",
            "Epoch 28/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6798\n",
            "Epoch 29/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6793\n",
            "Epoch 30/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.6788\n",
            "Epoch 31/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6783\n",
            "Epoch 32/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6778\n",
            "Epoch 33/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6773\n",
            "Epoch 34/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.6768\n",
            "Epoch 35/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6763\n",
            "Epoch 36/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6758\n",
            "Epoch 37/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6753\n",
            "Epoch 38/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6749\n",
            "Epoch 39/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6744\n",
            "Epoch 40/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6739\n",
            "Epoch 41/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6734\n",
            "Epoch 42/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6729\n",
            "Epoch 43/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6724\n",
            "Epoch 44/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6719\n",
            "Epoch 45/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6714\n",
            "Epoch 46/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6710\n",
            "Epoch 47/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6705\n",
            "Epoch 48/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6700\n",
            "Epoch 49/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6695\n",
            "Epoch 50/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.6690\n",
            "Epoch 51/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6685\n",
            "Epoch 52/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6681\n",
            "Epoch 53/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6676\n",
            "Epoch 54/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6671\n",
            "Epoch 55/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6666\n",
            "Epoch 56/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6661\n",
            "Epoch 57/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6656\n",
            "Epoch 58/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6652\n",
            "Epoch 59/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6647\n",
            "Epoch 60/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6642\n",
            "Epoch 61/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6637\n",
            "Epoch 62/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6632\n",
            "Epoch 63/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6628\n",
            "Epoch 64/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6623\n",
            "Epoch 65/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6618\n",
            "Epoch 66/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.6613\n",
            "Epoch 67/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.6608\n",
            "Epoch 68/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.6604\n",
            "Epoch 69/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.6599\n",
            "Epoch 70/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.6594\n",
            "Epoch 71/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.6589\n",
            "Epoch 72/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.6585\n",
            "Epoch 73/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.6580\n",
            "Epoch 74/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.6575\n",
            "Epoch 75/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.6570\n",
            "Epoch 76/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.6566\n",
            "Epoch 77/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.6561\n",
            "Epoch 78/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.6556\n",
            "Epoch 79/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.6551\n",
            "Epoch 80/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.6547\n",
            "Epoch 81/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.6542\n",
            "Epoch 82/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.6537\n",
            "Epoch 83/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.6532\n",
            "Epoch 84/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.6528\n",
            "Epoch 85/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.6523\n",
            "Epoch 86/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.6518\n",
            "Epoch 87/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.6514\n",
            "Epoch 88/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6509\n",
            "Epoch 89/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6504\n",
            "Epoch 90/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6499\n",
            "Epoch 91/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6495\n",
            "Epoch 92/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6490\n",
            "Epoch 93/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6485\n",
            "Epoch 94/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6481\n",
            "Epoch 95/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6476\n",
            "Epoch 96/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.6471\n",
            "Epoch 97/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.6467\n",
            "Epoch 98/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.6462\n",
            "Epoch 99/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.6457\n",
            "Epoch 100/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6453\n",
            "Epoch 101/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6448\n",
            "Epoch 102/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6443\n",
            "Epoch 103/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6439\n",
            "Epoch 104/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6434\n",
            "Epoch 105/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6429\n",
            "Epoch 106/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6425\n",
            "Epoch 107/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6420\n",
            "Epoch 108/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6416\n",
            "Epoch 109/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6411\n",
            "Epoch 110/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6406\n",
            "Epoch 111/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.6402\n",
            "Epoch 112/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6397\n",
            "Epoch 113/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6392\n",
            "Epoch 114/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.6388\n",
            "Epoch 115/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6383\n",
            "Epoch 116/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6379\n",
            "Epoch 117/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6374\n",
            "Epoch 118/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6369\n",
            "Epoch 119/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6365\n",
            "Epoch 120/120\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6360\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a0cb5d7cc10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions**\n",
        "# Single Predictions"
      ],
      "metadata": {
        "id": "NkPvbJfgdhIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ann.predict(sc.transform([[0.0, 1.0, 0.0, 501, 0, 32, 2, 0.0, 4, 1, 545501]])) > 0.5)\n"
      ],
      "metadata": {
        "id": "Bk6CpBzGdoG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59916eb8-fed0-473f-fd16-32986a3281d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "[[ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on testset"
      ],
      "metadata": {
        "id": "EvyfTzItdq5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred=ann.predict(x_test)\n",
        "y_pred=(y_pred>0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "ZKozXcODduHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a86bad-fbc7-43ae-f2a0-1caadfdf9850"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "[[0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "MqvqnXXWdweW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "79Ppd8T4dzbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161007fd-c6f5-4a52-8fff-3cfb209cde53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [1 0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}